View(station_occupation)
sum(which(station_occupation$salinity != -88))
length(station_occupation)
sum(which(station_occupation$salinity != -88.00))
count(which(station_occupation$salinity != -88.00))
nrow(which(station_occupation$salinity != -88.00))
nrow(filter(station_occupation$salinity != -88.00))
nrow(dplyr::filter(station_occupation$salinity != -88.00))
View(DB_rhmp)
length(unique(DB_rhmp$StationID))
save(DB_rhmp, "data/rhmp_data.csv")
save(DB_rhmp, "data/rhmp_data.RData")
DB_rhmp <- DB_grab %>%
dplyr::inner_join(DB_station_occupation, by = c('StationID','sampledate' = 'occupationdate')) %>%
dplyr::inner_join(DB_infauna, by = c('StationID','sampledate')) %>%
dplyr::select('StationID','replicate','sampledate','latitude','longitude','taxon','abundance','salinity', 'stratum', 'exclude') %>%
dplyr::mutate_if(is.numeric, list(~na_if(., -88))) %>%
dplyr::rename(species = taxon) %>%
dplyr::rename(Replicate = replicate, SampleDate = sampledate, Latitude = latitude, Longitude = longitude, Species = species, Abundance = abundance, Salinity = salinity, Stratum = stratum, Exclude = exclude)
length(unique(DB_rhmp$StationID))
save(DB_rhmp, file = "data/rhmp_data.RData")
getwd()
source('P:/PartTimers/JoanaPerdomo/Projects/SQOUnified/R/SQOUnified.R', echo=TRUE)
source('P:/PartTimers/JoanaPerdomo/Projects/SQOUnified/R/BRI.R', echo=TRUE)
source('P:/PartTimers/JoanaPerdomo/Projects/SQOUnified/R/RBI.R', echo=TRUE)
source('P:/PartTimers/JoanaPerdomo/Projects/SQOUnified/R/IBI.R', echo=TRUE)
source('P:/PartTimers/JoanaPerdomo/Projects/SQOUnified/R/MAMBI.R', echo=TRUE)
source('P:/PartTimers/JoanaPerdomo/Projects/SQOUnified/R/EQR.R', echo=TRUE)
SQO = "all"
EG_File_Name="data/Ref - EG Values 2018.csv";EG_Scheme="Hybrid"
# Compute ALL SQO scores
if (SQO == "all"){
mambi.score <- MAMBI(DB, EG_File_Name="data/Ref - EG Values 2018.csv", EG_Scheme="Hybrid") %>%
dplyr::rename(B13_Stratum = Stratum) %>%
dplyr::mutate(Score = MAMBI_Score, Category = New_MAMBI_Condition) %>%
dplyr::mutate(Category_Score = case_when(Category == "Reference" ~ 1, Category == "Low Disturbance" ~ 2, Category == "Moderate Disturbance" ~ 3, Category == "High Disturbance" ~ 4))
rbi.scores <- RBI(DB)
ibi.scores <- IBI(DB)
bri.scores <- BRI(DB)
# We need to incorporate RIVPACS. Once we have this we will take the median of RIVPACS, IBI, BRI, RBI and report back one overall score (MBI?)
# Once this is done, we will add this to the final output.
# For RIVPACS, we're simply going to write a wrapper function and add this to SQOUnified.
# If you run into problems, call D. Gillet to get more clarifaction.
final.scores <- mambi.score %>%
dplyr::full_join(bri.scores) %>%
dplyr::full_join(rbi.scores) %>%
dplyr::full_join(ibi.scores) %>% # will add other scores to this data frame as they are computed
dplyr::select("StationID", "Replicate", "SampleDate", "B13_Stratum", "Index", "Score",
"Category", "Category_Score", "Use_MAMBI") %>%
dplyr::arrange(StationID, SampleDate, Replicate)
} else {
mambi.score <- MAMBI(DB, EG_File_Name="data/Ref - EG Values 2018.csv", EG_Scheme="Hybrid")
final.scores <- mambi.score %>%
dplyr::left_join(rbi.scores, by = c("StationID", "Replicate")) %>%
dplyr::left_join(ibi.scores, by = c("StationID", "Replicate")) %>%
dplyr::left_join(bri.scores, by = c("StationID", "Replicate")) %>%
dplyr::group_by(StationID, SampleDate, Replicate)
# will add other scores to this data frame as they are computed
}
View(benthic_data)
# Create the dataset needed to compute all the SQO benthic indices
benthic_data <- grab %>%
dplyr::inner_join(station_occupation, by = c('stationid','sampledate' = 'occupationdate')) %>%
dplyr::inner_join(infauna, by = c('stationid','sampledate')) %>%
dplyr::select('stationid','replicate','sampledate','latitude','longitude','taxon','abundance','salinity', 'stratum', 'exclude') %>%
dplyr::mutate_if(is.numeric, list(~na_if(., -88))) %>%
dplyr::rename(species = taxon) %>%
dplyr::rename(StationID = stationid, Replicate = replicate, SampleDate = sampledate, Latitude = latitude, Longitude = longitude, Species = species, Abundance = abundance, Salinity = salinity, Stratum = stratum, Exclude = exclude)
save(benthic_data, file = "data/benthic_data_BenthicNoFilter.Rdata")
write.csv(benthic_data, file = "data/benthic_data_BenthicNoFilter.csv", row.names = FALSE)
load("P:/PartTimers/JoanaPerdomo/Projects/SQOUnified/data/benthic_data_BenthicNoFilter.Rdata")
DB = benthic_data
# Compute ALL SQO scores
if (SQO == "all"){
mambi.score <- MAMBI(DB, EG_File_Name="data/Ref - EG Values 2018.csv", EG_Scheme="Hybrid") %>%
dplyr::rename(B13_Stratum = Stratum) %>%
dplyr::mutate(Score = MAMBI_Score, Category = New_MAMBI_Condition) %>%
dplyr::mutate(Category_Score = case_when(Category == "Reference" ~ 1, Category == "Low Disturbance" ~ 2, Category == "Moderate Disturbance" ~ 3, Category == "High Disturbance" ~ 4))
rbi.scores <- RBI(DB)
ibi.scores <- IBI(DB)
bri.scores <- BRI(DB)
# We need to incorporate RIVPACS. Once we have this we will take the median of RIVPACS, IBI, BRI, RBI and report back one overall score (MBI?)
# Once this is done, we will add this to the final output.
# For RIVPACS, we're simply going to write a wrapper function and add this to SQOUnified.
# If you run into problems, call D. Gillet to get more clarifaction.
final.scores <- mambi.score %>%
dplyr::full_join(bri.scores) %>%
dplyr::full_join(rbi.scores) %>%
dplyr::full_join(ibi.scores) %>% # will add other scores to this data frame as they are computed
dplyr::select("StationID", "Replicate", "SampleDate", "B13_Stratum", "Index", "Score",
"Category", "Category_Score", "Use_MAMBI") %>%
dplyr::arrange(StationID, SampleDate, Replicate)
} else {
mambi.score <- MAMBI(DB, EG_File_Name="data/Ref - EG Values 2018.csv", EG_Scheme="Hybrid")
final.scores <- mambi.score %>%
dplyr::left_join(rbi.scores, by = c("StationID", "Replicate")) %>%
dplyr::left_join(ibi.scores, by = c("StationID", "Replicate")) %>%
dplyr::left_join(bri.scores, by = c("StationID", "Replicate")) %>%
dplyr::group_by(StationID, SampleDate, Replicate)
# will add other scores to this data frame as they are computed
}
length(unique(benthic_data$StationID))
View(assignment)
benthic_data <- grab %>%
dplyr::inner_join(station_occupation, by = c('stationid','sampledate' = 'occupationdate')) %>%
dplyr::inner_join(infauna, by = c('stationid','sampledate')) %>%
dplyr::select('stationid','replicate','sampledate','latitude','longitude','taxon','abundance','salinity', 'stratum', 'exclude') %>%
dplyr::mutate_if(is.numeric, list(~na_if(., -88))) %>%
dplyr::rename(species = taxon) %>%
dplyr::rename(StationID = stationid, Replicate = replicate, SampleDate = sampledate, Latitude = latitude, Longitude = longitude, Species = species, Abundance = abundance, Salinity = salinity, Stratum = stratum, Exclude = exclude)
View(benthic_data)
unique(benthic_data$Salinity)
save(benthic_data, file = "data/benthic_data.Rdata")
write.csv(benthic_data, file = "data/benthic_data.csv", row.names = FALSE)
load("P:/PartTimers/JoanaPerdomo/Projects/SQOUnified/data/benthic_data.Rdata")
DB = benthic_data
# Compute ALL SQO scores
if (SQO == "all"){
mambi.score <- MAMBI(DB, EG_File_Name="data/Ref - EG Values 2018.csv", EG_Scheme="Hybrid") %>%
dplyr::rename(B13_Stratum = Stratum) %>%
dplyr::mutate(Score = MAMBI_Score, Category = New_MAMBI_Condition) %>%
dplyr::mutate(Category_Score = case_when(Category == "Reference" ~ 1, Category == "Low Disturbance" ~ 2, Category == "Moderate Disturbance" ~ 3, Category == "High Disturbance" ~ 4))
rbi.scores <- RBI(DB)
ibi.scores <- IBI(DB)
bri.scores <- BRI(DB)
# We need to incorporate RIVPACS. Once we have this we will take the median of RIVPACS, IBI, BRI, RBI and report back one overall score (MBI?)
# Once this is done, we will add this to the final output.
# For RIVPACS, we're simply going to write a wrapper function and add this to SQOUnified.
# If you run into problems, call D. Gillet to get more clarifaction.
final.scores <- mambi.score %>%
dplyr::full_join(bri.scores) %>%
dplyr::full_join(rbi.scores) %>%
dplyr::full_join(ibi.scores) %>% # will add other scores to this data frame as they are computed
dplyr::select("StationID", "Replicate", "SampleDate", "B13_Stratum", "Index", "Score",
"Category", "Category_Score", "Use_MAMBI") %>%
dplyr::arrange(StationID, SampleDate, Replicate)
} else {
mambi.score <- MAMBI(DB, EG_File_Name="data/Ref - EG Values 2018.csv", EG_Scheme="Hybrid")
final.scores <- mambi.score %>%
dplyr::left_join(rbi.scores, by = c("StationID", "Replicate")) %>%
dplyr::left_join(ibi.scores, by = c("StationID", "Replicate")) %>%
dplyr::left_join(bri.scores, by = c("StationID", "Replicate")) %>%
dplyr::group_by(StationID, SampleDate, Replicate)
# will add other scores to this data frame as they are computed
}
rbi.scores <- RBI(DB)
load("P:/PartTimers/JoanaPerdomo/Projects/SQOUnified/data/TidalFresh_Standards.Rdata")
load("P:/PartTimers/JoanaPerdomo/Projects/SQOUnified/data/Taxonomic_Info.Rdata")
load("P:/PartTimers/JoanaPerdomo/Projects/SQOUnified/data/Saline_Standards.Rdata")
load("P:/PartTimers/JoanaPerdomo/Projects/SQOUnified/data/EG_Ref.Rdata")
# Compute ALL SQO scores
if (SQO == "all"){
mambi.score <- MAMBI(DB, EG_File_Name="data/Ref - EG Values 2018.csv", EG_Scheme="Hybrid") %>%
dplyr::rename(B13_Stratum = Stratum) %>%
dplyr::mutate(Score = MAMBI_Score, Category = New_MAMBI_Condition) %>%
dplyr::mutate(Category_Score = case_when(Category == "Reference" ~ 1, Category == "Low Disturbance" ~ 2, Category == "Moderate Disturbance" ~ 3, Category == "High Disturbance" ~ 4))
rbi.scores <- RBI(DB)
ibi.scores <- IBI(DB)
bri.scores <- BRI(DB)
# We need to incorporate RIVPACS. Once we have this we will take the median of RIVPACS, IBI, BRI, RBI and report back one overall score (MBI?)
# Once this is done, we will add this to the final output.
# For RIVPACS, we're simply going to write a wrapper function and add this to SQOUnified.
# If you run into problems, call D. Gillet to get more clarifaction.
final.scores <- mambi.score %>%
dplyr::full_join(bri.scores) %>%
dplyr::full_join(rbi.scores) %>%
dplyr::full_join(ibi.scores) %>% # will add other scores to this data frame as they are computed
dplyr::select("StationID", "Replicate", "SampleDate", "B13_Stratum", "Index", "Score",
"Category", "Category_Score", "Use_MAMBI") %>%
dplyr::arrange(StationID, SampleDate, Replicate)
} else {
mambi.score <- MAMBI(DB, EG_File_Name="data/Ref - EG Values 2018.csv", EG_Scheme="Hybrid")
final.scores <- mambi.score %>%
dplyr::left_join(rbi.scores, by = c("StationID", "Replicate")) %>%
dplyr::left_join(ibi.scores, by = c("StationID", "Replicate")) %>%
dplyr::left_join(bri.scores, by = c("StationID", "Replicate")) %>%
dplyr::group_by(StationID, SampleDate, Replicate)
# will add other scores to this data frame as they are computed
}
source('P:/PartTimers/JoanaPerdomo/Projects/SQOUnified/R/MAMBI.R', echo=TRUE)
# Compute ALL SQO scores
if (SQO == "all"){
mambi.score <- MAMBI(DB, EG_File_Name="data/Ref - EG Values 2018.csv", EG_Scheme="Hybrid") %>%
dplyr::rename(B13_Stratum = Stratum) %>%
dplyr::mutate(Score = MAMBI_Score, Category = New_MAMBI_Condition) %>%
dplyr::mutate(Category_Score = case_when(Category == "Reference" ~ 1, Category == "Low Disturbance" ~ 2, Category == "Moderate Disturbance" ~ 3, Category == "High Disturbance" ~ 4))
rbi.scores <- RBI(DB)
ibi.scores <- IBI(DB)
bri.scores <- BRI(DB)
# We need to incorporate RIVPACS. Once we have this we will take the median of RIVPACS, IBI, BRI, RBI and report back one overall score (MBI?)
# Once this is done, we will add this to the final output.
# For RIVPACS, we're simply going to write a wrapper function and add this to SQOUnified.
# If you run into problems, call D. Gillet to get more clarifaction.
final.scores <- mambi.score %>%
dplyr::full_join(bri.scores) %>%
dplyr::full_join(rbi.scores) %>%
dplyr::full_join(ibi.scores) %>% # will add other scores to this data frame as they are computed
dplyr::select("StationID", "Replicate", "SampleDate", "B13_Stratum", "Index", "Score",
"Category", "Category_Score", "Use_MAMBI") %>%
dplyr::arrange(StationID, SampleDate, Replicate)
} else {
mambi.score <- MAMBI(DB, EG_File_Name="data/Ref - EG Values 2018.csv", EG_Scheme="Hybrid")
final.scores <- mambi.score %>%
dplyr::left_join(rbi.scores, by = c("StationID", "Replicate")) %>%
dplyr::left_join(ibi.scores, by = c("StationID", "Replicate")) %>%
dplyr::left_join(bri.scores, by = c("StationID", "Replicate")) %>%
dplyr::group_by(StationID, SampleDate, Replicate)
# will add other scores to this data frame as they are computed
}
source('P:/PartTimers/JoanaPerdomo/Projects/SQOUnified/R/MAMBI.R', echo=TRUE)
# Compute ALL SQO scores
if (SQO == "all"){
mambi.score <- MAMBI(DB, EG_File_Name="data/Ref - EG Values 2018.csv", EG_Scheme="Hybrid") %>%
dplyr::rename(B13_Stratum = Stratum) %>%
dplyr::mutate(Score = MAMBI_Score, Category = New_MAMBI_Condition) %>%
dplyr::mutate(Category_Score = case_when(Category == "Reference" ~ 1, Category == "Low Disturbance" ~ 2, Category == "Moderate Disturbance" ~ 3, Category == "High Disturbance" ~ 4))
rbi.scores <- RBI(DB)
ibi.scores <- IBI(DB)
bri.scores <- BRI(DB)
# We need to incorporate RIVPACS. Once we have this we will take the median of RIVPACS, IBI, BRI, RBI and report back one overall score (MBI?)
# Once this is done, we will add this to the final output.
# For RIVPACS, we're simply going to write a wrapper function and add this to SQOUnified.
# If you run into problems, call D. Gillet to get more clarifaction.
final.scores <- mambi.score %>%
dplyr::full_join(bri.scores) %>%
dplyr::full_join(rbi.scores) %>%
dplyr::full_join(ibi.scores) %>% # will add other scores to this data frame as they are computed
dplyr::select("StationID", "Replicate", "SampleDate", "B13_Stratum", "Index", "Score",
"Category", "Category_Score", "Use_MAMBI") %>%
dplyr::arrange(StationID, SampleDate, Replicate)
} else {
mambi.score <- MAMBI(DB, EG_File_Name="data/Ref - EG Values 2018.csv", EG_Scheme="Hybrid")
final.scores <- mambi.score %>%
dplyr::left_join(rbi.scores, by = c("StationID", "Replicate")) %>%
dplyr::left_join(ibi.scores, by = c("StationID", "Replicate")) %>%
dplyr::left_join(bri.scores, by = c("StationID", "Replicate")) %>%
dplyr::group_by(StationID, SampleDate, Replicate)
# will add other scores to this data frame as they are computed
}
BenthicData = DB
# Compute ALL SQO scores
if (SQO == "all"){
mambi.score <- MAMBI(DB, EG_File_Name="data/Ref - EG Values 2018.csv", EG_Scheme="Hybrid") %>%
dplyr::rename(B13_Stratum = Stratum) %>%
dplyr::mutate(Score = MAMBI_Score, Category = New_MAMBI_Condition) %>%
dplyr::mutate(Category_Score = case_when(Category == "Reference" ~ 1, Category == "Low Disturbance" ~ 2, Category == "Moderate Disturbance" ~ 3, Category == "High Disturbance" ~ 4))
rbi.scores <- RBI(DB)
ibi.scores <- IBI(DB)
bri.scores <- BRI(DB)
# We need to incorporate RIVPACS. Once we have this we will take the median of RIVPACS, IBI, BRI, RBI and report back one overall score (MBI?)
# Once this is done, we will add this to the final output.
# For RIVPACS, we're simply going to write a wrapper function and add this to SQOUnified.
# If you run into problems, call D. Gillet to get more clarifaction.
final.scores <- mambi.score %>%
dplyr::full_join(bri.scores) %>%
dplyr::full_join(rbi.scores) %>%
dplyr::full_join(ibi.scores) %>% # will add other scores to this data frame as they are computed
dplyr::select("StationID", "Replicate", "SampleDate", "B13_Stratum", "Index", "Score",
"Category", "Category_Score", "Use_MAMBI") %>%
dplyr::arrange(StationID, SampleDate, Replicate)
} else {
mambi.score <- MAMBI(DB, EG_File_Name="data/Ref - EG Values 2018.csv", EG_Scheme="Hybrid")
final.scores <- mambi.score %>%
dplyr::left_join(rbi.scores, by = c("StationID", "Replicate")) %>%
dplyr::left_join(ibi.scores, by = c("StationID", "Replicate")) %>%
dplyr::left_join(bri.scores, by = c("StationID", "Replicate")) %>%
dplyr::group_by(StationID, SampleDate, Replicate)
# will add other scores to this data frame as they are computed
}
Input_File.0<-BenthicData %>%
dplyr::mutate(Species_ended_in_sp=(str_detect(Species," sp$")), Taxon=(str_replace(Species, " sp$",""))) %>%
dplyr::mutate(Coast=(ifelse(Longitude<=-115,"West","Gulf-East")))%>%
dplyr::mutate(SalZone=case_when(Salinity>30&Salinity<=40&Coast=="Gulf-East"~"EH", Salinity>18&Salinity<=30&Coast=="Gulf-East"~"PH", Salinity>5&Salinity<=18~"MH",
Salinity>0.2&Salinity<=5~"OH", Salinity>=0&Salinity<=0.2~"TF", Salinity>40~"HH",
Salinity>30&Salinity<=40&Coast=="West"~"WEH", Salinity>18&Salinity<=30&Coast=="West"~"WPH"))
EG_Ref<-read.csv(EG_File_Name, stringsAsFactors = F, na.strings = "") %>% select(.,Taxon, Exclude, EG=EG_Scheme) %>% mutate(EG=(ifelse(Taxon=="Oligochaeta", "V", EG)))
azoic.samples<-Input_File.0 %>% dplyr::filter(Taxon=="No Organisms Present") %>%
dplyr::select(StationID, Replicate, SampleDate, Latitude, Longitude, SalZone, Stratum) %>%
dplyr::mutate(if(is_empty(azoic.samples != TRUE)) {AMBI_Score = 7  & S=0 & H=0 & Oligo_pct=0 & MAMBI_Score=0 & Orig_MAMBI_Condition="Bad" & New_MAMBI_Condition="High Disturbance" & Use_MAMBI="Yes" & Use_AMBI="Yes - Azoic" & YesEG=NA})
azoic.samples<-Input_File.0 %>% dplyr::filter(Taxon=="No Organisms Present") %>%
dplyr::select(StationID, Replicate, SampleDate, Latitude, Longitude, SalZone, Stratum)
azoic.samples <- dplyr::mutate(if(is_empty(azoic.samples != TRUE)) {AMBI_Score = 7  & S=0 & H=0 & Oligo_pct=0 & MAMBI_Score=0 & Orig_MAMBI_Condition="Bad" & New_MAMBI_Condition="High Disturbance" & Use_MAMBI="Yes" & Use_AMBI="Yes - Azoic" & YesEG=NA})
azoic.samples <- dplyr::mutate(if(is.empty(azoic.samples != TRUE)) {AMBI_Score = 7  & S=0 & H=0 & Oligo_pct=0 & MAMBI_Score=0 & Orig_MAMBI_Condition="Bad" & New_MAMBI_Condition="High Disturbance" & Use_MAMBI="Yes" & Use_AMBI="Yes - Azoic" & YesEG=NA})
azoic.samples <- dplyr::mutate(if(empty(azoic.samples != TRUE)) {AMBI_Score = 7  & S=0 & H=0 & Oligo_pct=0 & MAMBI_Score=0 & Orig_MAMBI_Condition="Bad" & New_MAMBI_Condition="High Disturbance" & Use_MAMBI="Yes" & Use_AMBI="Yes - Azoic" & YesEG=NA})
View(azoic.samples)
azoic.samples <- dplyr::mutate(if(is.empty(azoic.samples != TRUE)) {AMBI_Score = 7  & S=0 & H=0 & Oligo_pct=0 & MAMBI_Score=0 & Orig_MAMBI_Condition="Bad" & New_MAMBI_Condition="High Disturbance" & Use_MAMBI="Yes" & Use_AMBI="Yes - Azoic" & YesEG=NA})
load("P:/PartTimers/JoanaPerdomo/Projects/SQO_Rivpacs/SccwrpRivpacs/data/SFBayExample.RData")
View(sfbay.example.taxa)
load("P:/PartTimers/JoanaPerdomo/Projects/SQO_Rivpacs/SccwrpRivpacs/data/SoCalExample.RData")
View(sfbay.example.taxa)
View(socal.example.habitat)
load("P:/PartTimers/JoanaPerdomo/Projects/SQOUnified/data/benthic_data.Rdata")
View(benthic_data)
View(benthic_data)
load("P:/PartTimers/JoanaPerdomo/Projects/SQOUnified/data/assignment.RData")
View(assignment)
load("P:/PartTimers/JoanaPerdomo/Projects/SQOUnified/data/assignment_data.Rdata")
load("P:/PartTimers/JoanaPerdomo/Projects/SQOUnified/data/EG_Ref.Rdata")
load("P:/PartTimers/JoanaPerdomo/Projects/SQOUnified/data/grab_data.Rdata")
View(grab)
load("P:/PartTimers/JoanaPerdomo/Projects/SQOUnified/data/infauna_data.Rdata")
View(infauna)
require(DBI) # needed to connect to database
require(dbplyr) # needed to connect to database
require(RPostgreSQL) # needed to connect to our database
require(rstudioapi) # just so we can type the password as we run the script, so it is not written in the clear
require(tidyverse)
# con is short for connection
# Create connection to the database
con <- DBI::dbConnect(
PostgreSQL(),
host = "192.168.1.16",
dbname = 'bight2018',
user = 'b18read',
password = '1969$Harbor' # if we post to github, we might want to do rstudioapi::askForPassword()
)
# Bring in our tables from the database
infauna <- tbl(con, "tbl_infaunalabundance_initial") %>% as_tibble
save(station_occupation, file = 'data/station_occupation_data.Rdata')
grab <- tbl(con, "tbl_grabevent") %>%
as_tibble %>%
dplyr::filter(grabeventnumber == 1)
assignment <- tbl(con, "field_assignment_table") %>%
as_tibble %>%
dplyr::filter(stratum == "Bays" | stratum == "Ports" | stratum == "Estuaries" | stratum == "Brackish Estuaries")
station_occupation <- tbl(con, "tbl_stationoccupation") %>%
as_tibble %>%
inner_join(assignment, by = 'stationid')
# Create the dataset needed to compute all the SQO benthic indices
benthic_data <- grab %>%
dplyr::filter(benthicinfauna == 'Yes') %>%
dplyr::inner_join(station_occupation, by = c('stationid','sampledate' = 'occupationdate')) %>%
dplyr::inner_join(infauna, by = c('stationid','sampledate')) %>%
dplyr::select('stationid','replicate','sampledate','latitude','longitude', 'stationwaterdepth', 'taxon','abundance','salinity', 'stratum', 'exclude') %>%
dplyr::mutate_if(is.numeric, list(~na_if(., -88))) %>%
dplyr::rename(species = taxon) %>%
dplyr::rename(StationID = stationid, Replicate = replicate, SampleDate = sampledate, Latitude = latitude, Longitude = longitude, SampleDepth = stationwaterdepth, Species = species, Abundance = abundance, Salinity = salinity, Stratum = stratum, Exclude = exclude)
View(benthic_data)
save(benthic_data, file = "data/benthic_data.Rdata")
write.csv(benthic_data, file = "data/benthic_data.csv", row.names = FALSE)
load("P:/PartTimers/JoanaPerdomo/Projects/SQO_Rivpacs/SccwrpRivpacs/data/SoCalReference.RData")
View(socal.reference.group.means)
View(socal.reference.taxa)
View(EG_Ref)
View(station_occupation)
View(benthic_data)
View(assignment)
View(grab)
View(infauna)
station <- read.csv(paste(system.file(package = "SccwrpRivpacs"), "/extdata/TestAllSpeciesStationInfo.csv", sep = ""), stringsAsFactors = FALSE)
View(station)
benthic <- read.csv(paste(system.file(package = "SccwrpRivpacs"), "/extdata/TestAllSpeciesBenthicInfo.csv", sep = ""), stringsAsFactors = FALSE)
View(benthic)
load("~/Desktop/Projects/SQOUnified/data/benthic_data.Rdata")
View(benthic_data)
View(benthic_data)
length(unique(benthic_data$StationID))
require(DBI) # needed to connect to database
require(dbplyr) # needed to connect to database
require(RPostgreSQL) # needed to connect to our database
require(rstudioapi) # just so we can type the password as we run the script, so it is not written in the clear
require(tidyverse)
# con is short for connection
# Create connection to the database
con <- DBI::dbConnect(
PostgreSQL(),
host = "192.168.1.16",
dbname = 'bight2018',
user = 'b18read',
password = '1969$Harbor' # if we post to github, we might want to do rstudioapi::askForPassword()
)
require(DBI) # needed to connect to database
require(dbplyr) # needed to connect to database
require(RPostgreSQL) # needed to connect to our database
require(rstudioapi) # just so we can type the password as we run the script, so it is not written in the clear
require(tidyverse)
# con is short for connection
# Create connection to the database
con <- DBI::dbConnect(
PostgreSQL(),
host = "192.168.1.16",
dbname = 'bight2018',
user = 'b18read',
password = '1969$Harbor' # if we post to github, we might want to do rstudioapi::askForPassword()
)
# Bring in our tables from the database
infauna <- tbl(con, "tbl_infaunalabundance_initial") %>% as_tibble
View(infauna)
# con is short for connection
# Create connection to the database
con <- DBI::dbConnect(
PostgreSQL(),
host = "192.168.1.16",
dbname = 'bight2018',
user = 'b18read',
password = '1969$Harbor' # if we post to github, we might want to do rstudioapi::askForPassword()
)
require(DBI) # needed to connect to database
require(dbplyr) # needed to connect to database
library(DBI)
library(dbplyr)
library(RPostgreSQL)
library(rstudioapi)
library(tidyverse)
# con is short for connection
# Create connection to the database
con <- DBI::dbConnect(
PostgreSQL(),
host = "192.168.1.16",
dbname = 'bight2018',
user = 'b18read',
password = '1969$Harbor' # if we post to github, we might want to do rstudioapi::askForPassword()
)
# Bring in our tables from the database
infauna <- tbl(con, "tbl_infaunalabundance_initial") %>% as_tibble
save(infauna, file = 'data/infauna_data.Rdata')
grab <- tbl(con, "tbl_grabevent") %>%
as_tibble %>%
dplyr::filter(grabeventnumber == 1)
save(grab, file = 'data/grab_data.Rdata')
assignment <- tbl(con, "field_assignment_table") %>%
as_tibble %>%
dplyr::filter(stratum == "Bays" | stratum == "Ports" | stratum == "Estuaries" | stratum == "Brackish Estuaries" | stratum == "Marinas")
save(assignment, file = 'data/assignment_data.Rdata')
station_occupation <- tbl(con, "tbl_stationoccupation") %>%
as_tibble %>%
inner_join(assignment, by = 'stationid')
save(station_occupation, file = 'data/station_occupation_data.Rdata')
# Create the dataset needed to compute all the SQO benthic indices
benthic_data <- grab %>%
dplyr::filter(benthicinfauna == 'Yes') %>%
dplyr::inner_join(station_occupation, by = c('stationid','sampledate' = 'occupationdate')) %>%
dplyr::inner_join(infauna, by = c('stationid','sampledate')) %>%
dplyr::select('stationid','replicate','sampledate','latitude','longitude', 'stationwaterdepth', 'taxon','abundance','salinity', 'stratum', 'exclude') %>%
dplyr::mutate_if(is.numeric, list(~na_if(., -88))) %>%
dplyr::rename(species = taxon) %>%
dplyr::rename(StationID = stationid, Replicate = replicate, SampleDate = sampledate, Latitude = latitude, Longitude = longitude, SampleDepth = stationwaterdepth, Species = species, Abundance = abundance, Salinity = salinity, Stratum = stratum, Exclude = exclude)
save(benthic_data, file = "data/benthic_data.Rdata")
write.csv(benthic_data, file = "data/benthic_data.csv", row.names = FALSE)
RIVPACS_wrapper <- function(DB){
# Split to SoCal and SFBay.
## We are only working with SoCal data so we don't need to do this!
#scb.station <- station[toupper(station$HabitatCode) == "C", ]
#########################
# At this point of the SQOUnified package, we are only working with SoCal data so we don't need sfb
#sfb.station <- station[toupper(station$HabitatCode) == "D", ]
# If data exists for habitat, format data.
#if(nrow(scb.station) > 0) {
scb.predictors <- data.frame(Latitude = DB$Latitude,
Longitude = DB$Longitude,
SampleDepth = DB$SampleDepth) %>%
dplyr::distinct()
DB <- DB %>% dplyr::rename(Taxa = Species)
scb.taxa <- DB %>% dplyr::select(StationID, Latitude, Longitude, SampleDepth) %>%
dplyr::distinct()
row.names(scb.predictors) <- scb.taxa$StationID
scb.predictors <- as.matrix(scb.predictors)
# Don't need this line because all needed info is in DB data frame
# and we're only doing SCB data, so no need to classify them
#scb.taxa <- DB[DB$StationID %in% scb.station$StationID, ]
scb.taxa <- DB %>%
dplyr::filter(Replicate == 1) %>%
dplyr::select(StationID, Taxa, Abundance) %>%
dplyr::distinct()
scb.taxa$Taxa <- gsub(" ", "_", scb.taxa$Taxa, fixed = TRUE)
scb.taxa$Taxa <- gsub("(", "_", scb.taxa$Taxa, fixed = TRUE)
scb.taxa$Taxa <- gsub(")", "_", scb.taxa$Taxa, fixed = TRUE)
scb.taxa <- scb.taxa %>%
tidyr::pivot_wider(id_cols = "StationID", names_from = "Taxa",
values_from = "Abundance", values_fn = list(Abundance = list))
scb.taxa <- as.data.frame(scb.taxa)
scb.taxa <- scb.taxa[, -1]
colnames(scb.taxa) <- gsub("Abundance.", "", colnames(scb.taxa))
# Replace NAs with zero.
scb.taxa[scb.taxa == "NULL"] <- 0
scb.taxa = as.data.frame(lapply(scb.taxa, as.numeric))
row.names(scb.taxa) <- row.names(scb.predictors)
# RIVPACS calculations. By default the functions use the example user data.
socal <- SoCalRivpacs(observed.predictors = scb.predictors, observed.taxa = scb.taxa)
rivpacs.score <- socal$oe.table %>%
dplyr::select(stations, O.over.E) %>%
dplyr::rename(StationID = stations, Score = O.over.E) %>%
dplyr::mutate(Index = "RIVPACS") %>%
dplyr::mutate(Category = case_when((Score > 0.90 | Score < 1.10) ~ "Reference",
((Score > 0.74 & Score <= 0.90) | Score >= 1.10 & Score < 1.26) ~ "Low Disturbance",
((Score > 0.32 & Score <= 0.74) | (Score >= 1.26)) ~ "Moderate Disturbance",
(Score <= 0.32) ~ "High Disturbance")) %>%
dplyr::mutate(Category_Score = case_when(Category == "Reference" ~ 1,
Category == "Low Disturbance" ~ 2,
Category == "Moderate Disturbance" ~ 3,
Category == "High Disturbance" ~ 4))
return(rivpacs.score)
}
test = RIVPACS_wrapper(DB)
test = RIVPACS_wrapper(benthic_data)
source('~/Desktop/Projects/SQOUnified/R/SoCalRivpacs.R')
test = RIVPACS_wrapper(benthic_data)
load("~/Desktop/Projects/SQOUnified/data/benthic_data.Rdata")
View(benthic_data)
?median
DB = benthic_data
library(devtools)
library(usethis)
library(devtools)
devtools::install()
devtools::install()
devtools::install()
devtools::install()
load("~/Desktop/Projects/SQOUnified/data/benthic_data.Rdata")
"benthic_data"
devtools::install()
devtools::install()
